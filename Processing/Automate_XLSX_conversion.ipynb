{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maija\\Documents\\Python\\waterfrontmap\n"
     ]
    }
   ],
   "source": [
    "# import stuff\n",
    "import os\n",
    "os.chdir(\"C:\\\\Users\\\\Maija\\\\Documents\\\\Python\\\\waterfrontmap\")\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HOW TO USE \n",
    "# ???\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make DF become json \n",
    "def become_json(df):\n",
    "    newjson = [dict() for x in range(len(df))]\n",
    "    cols = list(df)\n",
    "    for row in range(len(df)):\n",
    "        for name in cols:\n",
    "            if \"numpy\" in str(type(df[name][row])):\n",
    "                newjson[row][name]= int(df[name][row])\n",
    "            else:\n",
    "                newjson[row][name]= df[name][row]\n",
    "            \n",
    "    return newjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LAYER TEXT \n",
    "file_name = 'Processing\\\\Text\\\\layer_text.csv'\n",
    "df = pd.read_csv(open(file_name),encoding='utf-8')\n",
    "layerdata = become_json(df)\n",
    "\n",
    "# SMIA TEXT\n",
    "file_name = 'Processing\\\\Text\\\\smia_text.csv'\n",
    "df = pd.read_csv(open(file_name),encoding='utf-8')\n",
    "smiadata = become_json(df)\n",
    "\n",
    "# MISC \n",
    "dataNames = {'human_readable_zone': 'Land use: ',\n",
    "'Perc_POC_P003009': 'Percent people of color: ',\n",
    "'% of Families Below Poverty Level': 'Percent below poverty level: ',\n",
    "'CATEGORY': 'Storm surge zone: ',\n",
    "'Median Household Income': 'Median household income: ',\n",
    "'hurricane': 'Hurricane evacuation zone: ',\n",
    "'perc_uninsured': 'Percent Uninsured'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# save data\n",
    "fulldata = dict()\n",
    "fulldata[\"layer\"] = layerdata\n",
    "fulldata[\"smia\"] = smiadata\n",
    "fulldata[\"dataNames\"] = dataNames\n",
    "# save data (pretty)\n",
    "output_file = 'Processing\\\\text\\\\general_text.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(fulldata, f, sort_keys=True,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file exists?\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# STORY \n",
    "file_name = 'Processing\\\\Text\\\\story_text.csv'\n",
    "print(\"file exists?\")\n",
    "print(os.path.isfile(file_name))\n",
    "df = pd.read_csv(open(file_name),encoding='utf-8')\n",
    "data = become_json(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "njson = len(data)\n",
    "print(njson)\n",
    "\n",
    "# manual \n",
    "zoomMat = [10,12,12,12,12,12,12,12];\n",
    "latMat = [-73.9978,-73.97256593122793,-73.93480042828487,-74.23091192935536,\n",
    "-74.00743616089453,-73.8939875925258,-74.01499944630518,-74.13713363755667]; \n",
    "lngMat = [40.7209,40.70337539892057, 40.73043814252142, 40.5505517824447\n",
    ", 40.68650785503232, 40.80730643781723, 40.658442081047724, 40.64057887695694]; \n",
    "\n",
    "# add zoom, lng and lat fields based on SMIA number\n",
    "# also count the first occurence of each SMIA \n",
    "SMIA_first_page = [0,0,0,0,0,0,0,0]\n",
    "for page in range(njson):\n",
    "    SMIA = data[page][\"pageSMIA\"]\n",
    "    data[page][\"pageZoom\"] = zoomMat[SMIA]\n",
    "    data[page][\"pageLng\"]  = lngMat[SMIA]\n",
    "    data[page][\"pageLat\"]  = latMat[SMIA]\n",
    "    if page>0:\n",
    "        if SMIA!=(data[page-1][\"pageSMIA\"]):\n",
    "            SMIA_first_page[SMIA] = page\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# format data\n",
    "fulldata = dict()\n",
    "fulldata[\"data\"] = data\n",
    "fulldata[\"global_max_page\"] = njson\n",
    "fulldata[\"SMIA_first_page\"] = SMIA_first_page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save data (pretty)\n",
    "output_file = 'Processing\\\\text\\\\story_text.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(fulldata, f, sort_keys=True,indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
