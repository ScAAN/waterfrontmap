{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stuff\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "path = \"C:\\\\Users\\\\Maija\\\\Documents\\\\waterfrontmap\"\n",
    "os.chdir(path)\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "# geocoding!\n",
    "import requests\n",
    "url = 'https://maps.googleapis.com/maps/api/geocode/json'\n",
    "url = 'http://maps.googleapis.com/maps/api/geocode/json?latlng=40.714224,-73.961452&sensor=false'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# geojson writing function \n",
    "# http://geoffboeing.com/2015/10/exporting-python-data-geojson/\n",
    "def df_to_geojson(df, properties, lat='latitude', lon='longitude'):\n",
    "    geojson = {'type':'FeatureCollection', 'features':[]}\n",
    "    for _, row in df.iterrows():\n",
    "        feature = {'type':'Feature',\n",
    "                   'properties':{},\n",
    "                   'geometry':{'type':'Point',\n",
    "                               'coordinates':[]}}\n",
    "        feature['geometry']['coordinates'] = [row[lon],row[lat]]\n",
    "        for prop in properties:\n",
    "            feature['properties'][prop] = row[prop]\n",
    "        geojson['features'].append(feature)\n",
    "    return geojson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded \"NotYetConverted\\NYS_NYC_MOSF.csv\" !\n",
      "contains 119 MOSF sites\n"
     ]
    }
   ],
   "source": [
    "# load CBS or MOSF or SUPERFUND2\n",
    "waste_type = 'MOSF'\n",
    "file_name = 'NotYetConverted\\\\NYS_NYC_' + waste_type + '.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "df[\"Full Address\"] = df[\"Site Address\"]+df[\"Locality\"]+\", New York City, NY\" #+df[\" ZipCode]\n",
    "\n",
    "print('loaded \"' + file_name + '\" !')\n",
    "print('contains ' +str(len(df.index)) + ' ' + waste_type + ' sites') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed 0 requests!\n"
     ]
    }
   ],
   "source": [
    "# geocode using requests\n",
    "numcoded = 0;\n",
    "for ind, row in enumerate(df[\"Full Address\"].values):\n",
    "    params = {'sensor': 'false', 'address': row}\n",
    "    \n",
    "    \n",
    "    if is_numeric_dtype(type(df.loc[ind, \" Latitude\"]))==0:\n",
    "        print(df.loc[ind, \" Latitude\"] + \" -> \" + str(float(df.loc[ind, \" Latitude\"])))\n",
    "        df.loc[ind, \" Latitude\"] = float(df.loc[ind, \" Latitude\"])\n",
    "    \n",
    "    if is_numeric_dtype(type(df.loc[ind, \" Longitude\"]))==0:\n",
    "        print(df.loc[ind, \" Longitude\"] + \" -> \" + str(float(df.loc[ind, \" Longitude\"])))\n",
    "        df.loc[ind, \" Longitude\"] = float(df.loc[ind, \" Longitude\"])\n",
    "    \n",
    "    if (pd.isnull(df.loc[ind, \" Latitude\"]) or pd.isnull(df.loc[ind, \" Longitude\"])):\n",
    "        numcoded +=1\n",
    "        print(numcoded)\n",
    "        r = requests.get(url, params=params)\n",
    "        results = r.json()['results']\n",
    "        while not results: \n",
    "            # if you give it too many requests it will refuse your requests\n",
    "            # so let's sloppily keep requesting instead\n",
    "            # update this to pause between requests to avoid hitting limit\n",
    "            r = requests.get(url, params=params)\n",
    "            results = r.json()['results']\n",
    "\n",
    "        location = results[0]['geometry']['location']\n",
    "        df.loc[ind,\" Latitude\"] = location['lat']\n",
    "        df.loc[ind,\" Longitude\"] = location['lng']\n",
    "\n",
    "        # display progress\n",
    "        #if ind % 100 ==0: \n",
    "        #    print('completed ' +str(ind+1) + '/'+ str(len(df.index)) +' requests!') \n",
    "#print('completed ' +str(ind+1) + '/'+ str(len(df.index)) +' requests!')   \n",
    "print('completed ' +str(numcoded) + ' requests!')   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as \"Data\\MOSF_converted.json\" !\n"
     ]
    }
   ],
   "source": [
    "# now write a geojson\n",
    "cols = ['Full Address']\n",
    "geojson = df_to_geojson(df, cols, lat=' Latitude', lon=' Longitude')\n",
    "output_filename = 'Data\\\\' +waste_type + '_converted.json'\n",
    "with open(output_filename, 'w') as output_file:\n",
    "    json.dump(geojson, output_file, indent=2) \n",
    "\n",
    "print('saved as \"'+ output_filename + '\" !')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after converting all sites... \n",
    "# combine all sites into one geojson\n",
    "import json \n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "with open('Data\\\\TRI_converted.json') as f:\n",
    "    tri_raw = json.load(f)\n",
    "with open('Data\\\\CBS_converted.json') as f:\n",
    "    cbs_raw = json.load(f)\n",
    "with open('Data\\\\MOSF_converted.json') as f:\n",
    "    mos_raw = json.load(f)\n",
    "with open('Data\\\\SUPERFUND2_converted.json') as f:\n",
    "    sup_raw = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate sites\n",
    "# (since we can't see them on the map since they're on top of each other)\n",
    "# and replace with the NUMBER_OF_SITES property\n",
    "def remove_duplicates(dict1):\n",
    "    seen = set()\n",
    "    seen_count = {}\n",
    "    seen_ind = {}\n",
    "    dup = []\n",
    "    print('removing duplicates in ' + str(len(dict1['features'])) + ' element list...')\n",
    "    for x in range(len(dict1['features'])):\n",
    "        cords = dict1['features'][x]['geometry']['coordinates']\n",
    "        cordstr = 'lat'+str(cords[0])+'lng'+str(cords[1])\n",
    "        if cordstr not in seen:\n",
    "            seen.add(cordstr)\n",
    "            seen_count[cordstr]=1\n",
    "            seen_ind[cordstr]=x\n",
    "        else:\n",
    "            dup.append(x)\n",
    "            seen_count[cordstr]=seen_count[cordstr]+1\n",
    "    for x in seen_count:\n",
    "        dict1['features'][seen_ind[x]]['properties']['NUMBER_OF_SITES'] = seen_count[x]\n",
    "        if seen_count[x]>1:\n",
    "            dict1['features'][seen_ind[x]]['properties']['NUM_SITES_STRING'] = str(seen_count[x])\n",
    "        else:\n",
    "            dict1['features'][seen_ind[x]]['properties']['NUM_SITES_STRING'] = \"\"\n",
    "    dict2 = copy.deepcopy(dict1)\n",
    "    for idx in sorted(dup, reverse=True):\n",
    "        del dict2['features'][idx]\n",
    "    print('...removed ' + str(len(dup)) + ' duplicates!')\n",
    "    #print(sorted(seen_count.values()))\n",
    "    return dict2, list(seen_count.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing duplicates in 1968 element list...\n",
      "...removed 1336 duplicates!\n",
      "removing duplicates in 86 element list...\n",
      "...removed 0 duplicates!\n",
      "removing duplicates in 119 element list...\n",
      "...removed 83 duplicates!\n",
      "removing duplicates in 45 element list...\n",
      "...removed 0 duplicates!\n"
     ]
    }
   ],
   "source": [
    "# remove duplicate sites and make a dict\n",
    "tri, tri_sc = remove_duplicates(tri_raw)\n",
    "cbs, cbs_sc = remove_duplicates(cbs_raw)\n",
    "mos, mos_sc = remove_duplicates(mos_raw)\n",
    "sup, sup_sc = remove_duplicates(sup_raw)\n",
    "mydict = {'TRI': tri, 'CBS': cbs, 'MOSF': mos, 'SUPERFUND2': sup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ead798b6d8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ead7954470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "all_counts = tri_sc+cbs_sc+mos_sc+sup_sc\n",
    "# check frequency of stacked sites and maximum number of stacked sites\n",
    "all_counts = [i for i in all_counts if i>1]\n",
    "sns.distplot(all_counts,kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRI\n",
      "632\n",
      "CBS\n",
      "86\n",
      "MOSF\n",
      "36\n",
      "SUPERFUND2\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "# put a site name on each site and add Full Address to TRI sites \n",
    "for myvar in mydict:\n",
    "    print(myvar)\n",
    "    varlen = len(mydict[myvar]['features'])\n",
    "    print(varlen)\n",
    "    for i in range(varlen):\n",
    "        mydict[myvar]['features'][i]['properties']['SITE_NAME'] = myvar\n",
    "        if myvar=='TRI':\n",
    "           mydict[myvar]['features'][i]['properties']['Full Address'] = mydict[myvar]['features'][i]['properties']['STREET_ADDRESS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as \"Data\\bulkstorage_converted.json\" !\n"
     ]
    }
   ],
   "source": [
    "# merge and save \n",
    "merged = tri\n",
    "merged['features'] = merged['features']+cbs['features']+mos['features']+sup['features']\n",
    "len(merged['features'])\n",
    "\n",
    "# now write a geojson\n",
    "output_filename = 'Data\\\\bulkstorage_converted.json'\n",
    "with open(output_filename, 'w') as output_file:\n",
    "    json.dump(merged, output_file, indent=2) \n",
    "print('saved as \"'+ output_filename + '\" !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
